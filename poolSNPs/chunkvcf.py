import sys, os
from typing import *
import numpy as np
from cyvcf2 import VCF
import pysam
from itertools import starmap, repeat
import shutil
import multiprocessing as mp
import argparse

home_dir = os.path.expanduser("~")
proj_dir = os.path.join(home_dir, '1000Genomes')
sys.path.insert(0, proj_dir)

from scripts.VCFPooling.poolSNPs import parameters as prm
from scripts.VCFPooling.poolSNPs import beagle_tools as bgltls
from scripts.VCFPooling.poolSNPs import pool
from scripts.VCFPooling.poolSNPs import dataframe as vcfdf

from persotools.files import delete_file, mkdir, FilePath
from persotools.struct import NamedDict

'''
Parallelized file processing: Read main vcf and write chunks
Implement for current cyvcf2-based pooling for now
Steps:
* 
*
*
'''


class PysamVariantCallGenerator(object):
    """
    Generates single-type formatted calls of variants
    """

    def __init__(self, vcfpath: FilePath, format: str = None):
        """
        :param vcfpath:
        :param indextype: identifier for variants: 'id', 'chrom:pos'.
        Must be 'chrom:pos' if the input has been generated by Phaser
        """
        self.path = vcfpath
        self.fmt = format

    def __iter__(self):
        vcfobj = pysam.VariantFile(self.path)
        for var in vcfobj:
            yield [g[self.fmt] for g in var.samples.values()]


class PysamVariantChunkGenerator(object):
    """
    Generates chunks of single-type formatted calls of variants
    """

    def __init__(self, vcfpath: FilePath, format: str = None, chunksize: int = None):
        """
        :param vcfpath:
        :param indextype: identifier for variants: 'id', 'chrom:pos'.
        Must be 'chrom:pos' if the input has been generated by Phaser
        """
        self.path = vcfpath
        self.fmt = format
        self.chksz = chunksize
        self.chrom = [*pysam.VariantFile(self.path).header.contigs][0]
        # extract chrom, works if only 1 chrom in the file
        self.pack = True
        self.newpos = 1  # for valid self.newpos - 1 at the start of the first chunk

    def chunk(self, chunksize: int, newpos: int):
        """Build generators of variants calls"""
        iterator = pysam.VariantFile(self.path)
        try:
            for i, v in enumerate(iterator.fetch(contig=self.chrom, start=newpos - 1, reopen=False)):
                # newpos - 1: avoids first variant truncation in the next chunk
                var = v
                if i == chunksize:
                    break
                yield var

        except StopIteration:
            print('Could not build chunk')

    def incrementer(self, chunksize: int):
        """update position and packing bool"""
        iterator = pysam.VariantFile(self.path)
        try:
            for i, v in enumerate(iterator.fetch(contig=self.chrom, start=self.newpos - 1, reopen=False)):
                # self.newpos - 1: avoids first variant truncation in the next chunk
                var = v
                if i == chunksize:
                    self.newpos = var.pos
                    break
            if var.pos != self.newpos:  # reached EOF
                self.pack = False

        except StopIteration:
            self.newpos = None
            self.pack = False

        finally:
            return self.newpos, self.pack

    def chunkpacker(self):
        while self.pack:
            chk = self.chunk(self.chksz, self.newpos)
            # function output and included sttributes updates NOT unpacked hence NOT updated
            self.newpos, self.pack = self.incrementer(self.chksz)
            yield chk
            print(self.newpos, self.pack)


class PysamChunkHandler(object):
    """
    what I will be able to do with chunks of variants:
    * track header of the main file, update header if necessary
    * process e.g. simualte pooling
    * write back to vcf
    """
    def __init__(self, mainpath: FilePath, packedchunk):
        self.mainf = pysam.VariantFile(mainpath)
        self.data = packedchunk

    @property
    def header(self):
        return self.mainf.header

    def process(self):
        # any way to update a record?
        for rec in self.data:
            var = rec
            for v in var.samples.values():
                v['GT'] = (None, None)
            yield var

    def writechunk(self, pathout: FilePath, data):
        """
        :param data: variant generator
        """
        fout = pysam.VariantFile(pathout, 'w', header=self.header)
        data = self.process()
        for rec in data:
            var = rec
            print([v['GT'] for v in var.samples.values()])
            fout.write(rec)
        fout.close()


class PysamVariantPooler(object):
    """
    Class translation of pool.process_line
    """
    def __init__(self, groups: list, simul: str, format: str,
                 w: pysam.VariantFile, v: pysam.VariantRecord,
                 dict_gl: dict,  write: bool = True):
        self.groups = groups
        self.simul = simul
        self.fmt = format
        self.writer = w
        self.record = v
        self.lookup = dict_gl
        self._write = write
        self.samples = self.record.samples.keys()
        self.genotypes = np.asarray(self.record.samples.values()[self.fmt])
        self.pooled_record = self.record.copy()
        self.blocks = []
        for gp in groups[0]:
            self.blocks.append(pool.SNPsPool().set_subset(gp))

    def simulate_pooling(self):
        self.pooled_record.format = prm.GTGL
        for p in self.blocks:
            p.set_line_values(self.samples, self.record)
            if prm.GTGL == 'GL' and prm.unknown_gl == 'adaptive':
                self.pooled_record = p.decode_genotypes_gl(self.genotypes, self.lookup)
            else:  # prm.GTGL == 'GT' or fixed GL
                self.pooled_record = p.decode_genotypes_gt(self.genotypes)

    def simulate_rdmissing(self):
        pass

    def write_variant(self):
        pass


class PysamFilePooler(object):
    """
    Class translation of pool.process_file
    modify header if GT pooled to GL
    """
    def __init__(self, data: pysam.VariantFile, groups: list, simul: str):
        self.data = data
        self.groups = groups
        self.simul = simul

    def adapt_gl(self):
        pass

    def process(self):
        pass


class CyvcfVariantCallGenerator(object):
    """
    Generates single-type formatted calls of variants
    """

    def __init__(self, vcfpath: FilePath, format: str = None):
        """
        :param vcfpath:
        :param indextype: identifier for variants: 'id', 'chrom:pos'.
        Must be 'chrom:pos' if the input has been generated by Phaser
        """
        self.path = vcfpath
        self.fmt = format

    def __iter__(self):
        vcfobj = VCF(self.path)
        return vcfobj


class CyvcfVariantChunkGenerator(object):
    """
    Generates chunks of single-type formatted calls of variants
    """

    def __init__(self, vcfpath: FilePath, format: str = None, chunksize: int = None):
        """
        :param vcfpath:
        :param indextype: identifier for variants: 'id', 'chrom:pos'.
        Must be 'chrom:pos' if the input has been generated by Phaser
        """
        self.path = vcfpath
        self.fmt = format
        self.chksz = chunksize
        self.chrom = [*VCF(self.path)][0].CHROM
        # extract chrom, works if only 1 chrom in the file
        self.pack = True
        self.newpos = 1  # for valid self.newpos - 1 at the start of the first chunk

    def chunk(self, chunksize: int, newpos: int):
        """Build generators of variants calls"""
        iterator = VCF(self.path)
        try:
            for i, v in enumerate(iterator.fetch(contig=self.chrom, start=newpos - 1, reopen=False)):
                # newpos - 1: avoids first variant truncation in the next chunk
                var = v
                if i == chunksize:
                    break
                yield var

        except StopIteration:
            print('Could not build chunk')

    def incrementer(self, chunksize: int):
        """update position and packing bool"""
        iterator = pysam.VariantFile(self.path)
        try:
            for i, v in enumerate(iterator.fetch(contig=self.chrom, start=self.newpos - 1, reopen=False)):
                # self.newpos - 1: avoids first variant truncation in the next chunk
                var = v
                if i == chunksize:
                    self.newpos = var.pos
                    break
            if var.pos != self.newpos:  # reached EOF
                self.pack = False

        except StopIteration:
            self.newpos = None
            self.pack = False

        finally:
            return self.newpos, self.pack

    def chunkpacker(self):
        while self.pack:
            chk = self.chunk(self.chksz, self.newpos)
            # function output and included sttributes updates NOT unpacked hence NOT updated
            self.newpos, self.pack = self.incrementer(self.chksz)
            yield chk
            print(self.newpos, self.pack)


class CyvcfChunkHandler(object):
    """
    what I will be able to do with chunks of variants:
    * track header of the main file, update header if necessary
    * process e.g. simualte pooling
    * write back to vcf
    """
    def __init__(self, mainpath: FilePath, packedchunk):
        self.mainf = pysam.VariantFile(mainpath)
        self.data = packedchunk

    @property
    def header(self):
        return self.mainf.header

    def process(self):
        # any way to update a record?
        for rec in self.data:
            var = rec
            for v in var.samples.values():
                v['GT'] = (None, None)
            yield var

    def writechunk(self, pathout: FilePath, data):
        """
        :param data: variant generator
        """
        fout = pysam.VariantFile(pathout, 'w', header=self.header)
        data = self.process()
        for rec in data:
            var = rec
            print([v['GT'] for v in var.samples.values()])
            fout.write(rec)
        fout.close()


class CyvcfVariantPooler(object):
    """
    Class translation of pool.process_line
    """
    def __init__(self, groups: list, simul: str, format: str,
                 w: pysam.VariantFile, v: pysam.VariantRecord,
                 dict_gl: dict,  write: bool = True):
        self.groups = groups
        self.simul = simul
        self.fmt = format
        self.writer = w
        self.record = v
        self.lookup = dict_gl
        self._write = write
        self.samples = self.record.samples.keys()
        self.genotypes = np.asarray(self.record.samples.values()[self.fmt])
        self.pooled_record = self.record.copy()
        self.blocks = []
        for gp in groups[0]:
            self.blocks.append(pool.SNPsPool().set_subset(gp))

    def simulate_pooling(self):
        self.pooled_record.format = prm.GTGL
        for p in self.blocks:
            p.set_line_values(self.samples, self.record)
            if prm.GTGL == 'GL' and prm.unknown_gl == 'adaptive':
                self.pooled_record = p.decode_genotypes_gl(self.genotypes, self.lookup)
            else:  # prm.GTGL == 'GT' or fixed GL
                self.pooled_record = p.decode_genotypes_gt(self.genotypes)

    def simulate_rdmissing(self):
        pass

    def write_variant(self):
        pass

if __name__ == '__main__':
    os.chdir('/home/camille/1000Genomes/data/gl/gl_adaptive/all_snps_all_samples')
    mainpth = 'IMP.chr20.pooled.beagle2.gl.chunk10000.corr.vcf.gz'

    pysamobj = vcfdf.PandasMixedVCF(mainpth, format='GP')
    pysamvar = PysamVariantCallGenerator(mainpth, format='GP')
    pysamchunk = PysamVariantChunkGenerator(mainpth, format='GP', chunksize=1000)

    cyvcfobj = vcfdf.PandasVCF(mainpth)
    cyvcfvar = CyvcfVariantCallGenerator(mainpth)
    cyvcfchunk = CyvcfVariantChunkGenerator(mainpth)

    chunkpack = pysamchunk.chunkpacker()
    for i, chk in enumerate(chunkpack):
        break
        # print(i, len([*chk]))  # empties chk!
        print('\r\n', i)
        chki = PysamChunkHandler(mainpth, chk)
        chki.writechunk('chktest{}.vcf'.format(i), chki.data)
        break

